{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, classification_report\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.regularizers import L1L2\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import Callback\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "import feather\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (12,13,14,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3436\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('SBA_All_Extra_Data.csv')\n",
    "df['LoanStatus'].replace('CHGOFF',1, inplace=True)\n",
    "df['LoanStatus'].replace('PIF',0, inplace=True)\n",
    "\n",
    "#Note: It is recommended to not change any of these parameters for performance improvement.\n",
    "#The only value that should be changed between runs is the year_thresh variable to see how\n",
    "#default probability modeling varies over different timespans.\n",
    "\n",
    "\n",
    "year_thresh = 5\n",
    "total = 0\n",
    "for i in range(len(df)):\n",
    "    if df.LoanStatus[i]  == 1:\n",
    "        start = datetime.strptime( df.loc[i, 'ApprovalDate'], \"%m/%d/%Y\")\n",
    "        end = datetime.strptime( df.loc[i, 'ChargeOffDate'], \"%m/%d/%Y\")\n",
    "        delta = (end - start).days\n",
    "        if delta / 365 > year_thresh:\n",
    "            df.loc[i, 'LoanStatus'] = 0\n",
    "        total += df.loc[i, 'LoanStatus']\n",
    "print(total)\n",
    "\n",
    "\n",
    "df['NaicsCode'].fillna( 0, inplace=True)\n",
    "ThirdPartyDollars_mean = df['ThirdPartyDollars'].mean(skipna = True)\n",
    "df['ThirdPartyDollars'].fillna(ThirdPartyDollars_mean, inplace = True)\n",
    "df['ThirdPartyLender_State'].fillna('Unknown', inplace = True)\n",
    "df['SectorCode'] = df['NaicsCode'].apply(lambda x: int(x*1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "Program\n",
      "BorrName\n",
      "BorrStreet\n",
      "BorrCity\n",
      "BorrState\n",
      "BorrZip\n",
      "CDC_Name\n",
      "CDC_Street\n",
      "CDC_City\n",
      "CDC_State\n",
      "CDC_Zip\n",
      "ThirdPartyLender_Name\n",
      "ThirdPartyLender_City\n",
      "ThirdPartyLender_State\n",
      "ThirdPartyDollars\n",
      "GrossApproval\n",
      "ApprovalDate\n",
      "ApprovalFiscalYear\n",
      "DeliveryMethod\n",
      "subpgmdesc\n",
      "InitialInterestRate\n",
      "TermInMonths\n",
      "NaicsCode\n",
      "NaicsDescription\n",
      "ProjectCounty\n",
      "ProjectState\n",
      "BusinessType\n",
      "LoanStatus\n",
      "ChargeOffDate\n",
      "GrossChargeOffAmount\n",
      "ag_Public_nom\n",
      "ag_Private_nom\n",
      "ag_Public_dollar\n",
      "ag_Private_dollar\n",
      "ag_Total\n",
      "cci_CCI\n",
      "cci_CCI_c\n",
      "creative_Metro_93\n",
      "creative_Metro_03\n",
      "creative_Employed\n",
      "creative_Creative\n",
      "creative_Arts\n",
      "creative_Creative_frac\n",
      "creative_Arts_frac\n",
      "farm_Num_Farms_Supply\n",
      "farm_NumShares\n",
      "farm_CSA_organic\n",
      "income_n1_1\n",
      "income_prep_1\n",
      "income_n2_1\n",
      "income_a00100_1\n",
      "income_a00200_1\n",
      "income_a00300_1\n",
      "income_a00600_1\n",
      "income_a00900_1\n",
      "income_n1_2\n",
      "income_prep_2\n",
      "income_n2_2\n",
      "income_a00100_2\n",
      "income_a00200_2\n",
      "income_a00300_2\n",
      "income_a00600_2\n",
      "income_a00900_2\n",
      "income_a18300_2\n",
      "income_a19700_2\n",
      "income_n1\n",
      "income_prep\n",
      "income_n2\n",
      "income_a00100\n",
      "income_a00200\n",
      "income_a00300\n",
      "income_a00600\n",
      "income_a00900\n",
      "income_a18300\n",
      "income_a19700\n",
      "income_n1_4\n",
      "income_prep_4\n",
      "income_n2_4\n",
      "income_a00100_4\n",
      "income_a00200_4\n",
      "income_a00300_4\n",
      "income_a00600_4\n",
      "income_a00900_4\n",
      "income_a18300_4\n",
      "income_a19700_4\n",
      "income_n1_5\n",
      "income_prep_5\n",
      "income_n2_5\n",
      "income_a00100_5\n",
      "income_a00200_5\n",
      "income_a00300_5\n",
      "income_a00600_5\n",
      "income_a00900_5\n",
      "income_a18300_5\n",
      "income_a19700_5\n",
      "income_n1_6\n",
      "income_prep_6\n",
      "income_n2_6\n",
      "income_a00100_6\n",
      "income_a00200_6\n",
      "income_a00300_6\n",
      "income_a00600_6\n",
      "income_a18300_6\n",
      "income_a19700_6\n",
      "patent_Patent\n",
      "patent_Patent_frac\n",
      "SP_Open\n",
      "SP_High\n",
      "SP_Low\n",
      "SP_Close\n",
      "SP_Adj_Close\n",
      "SP_Volume\n",
      "SP_Returns\n",
      "unemp_Rate\n",
      "unemp_Rate_c\n",
      "unemp_m_value\n",
      "unemp_m_value_c\n",
      "zillow_PctDecrease\n",
      "zillow_SizeRank\n",
      "zillow_PctDecrease_c\n",
      "zillow_ZHVI\n",
      "zillow_SizeRank.1\n",
      "zillow_ZHVI_c\n",
      "zillow_PctIncrease\n",
      "zillow_SizeRank.2\n",
      "zillow_PctIncrease_c\n",
      "zillow_MedianValue\n",
      "zillow_SizeRank.3\n",
      "zillow_MedianValue_c\n",
      "bci_BCI\n",
      "bci_BCI_c\n",
      "ed_cty_ENROLL\n",
      "ed_cty_TOTALREV\n",
      "ed_cty_TFEDREV\n",
      "ed_cty_TSTREV\n",
      "ed_cty_TLOCREV\n",
      "ed_cty_TOTALEXP\n",
      "ed_cty_TCURINST\n",
      "ed_cty_TCURSSVC\n",
      "ed_cty_TCURONON\n",
      "ed_cty_TCAPOUT\n",
      "ed_cty_ENROLL_c\n",
      "ed_cty_TOTALREV_c\n",
      "ed_cty_TFEDREV_c\n",
      "ed_cty_TSTREV_c\n",
      "ed_cty_TLOCREV_c\n",
      "ed_cty_TOTALEXP_c\n",
      "ed_cty_TCURINST_c\n",
      "ed_cty_TCURSSVC_c\n",
      "ed_cty_TCURONON_c\n",
      "ed_cty_TCAPOUT_c\n",
      "ed_st_ENROLL\n",
      "ed_st_TOTAL_REVENUE\n",
      "ed_st_FEDERAL_REVENUE\n",
      "ed_st_STATE_REVENUE\n",
      "ed_st_LOCAL_REVENUE\n",
      "ed_st_TOTAL_EXPENDITURE\n",
      "ed_st_INSTRUCTION_EXPENDITURE\n",
      "ed_st_SUPPORT_SERVICES_EXPENDITURE\n",
      "ed_st_OTHER_EXPENDITURE\n",
      "ed_st_CAPITAL_OUTLAY_EXPENDITURE\n",
      "ed_st_ENROLL_c\n",
      "ed_st_TOTAL_REVENUE_c\n",
      "ed_st_FEDERAL_REVENUE_c\n",
      "ed_st_STATE_REVENUE_c\n",
      "ed_st_LOCAL_REVENUE_c\n",
      "ed_st_TOTAL_EXPENDITURE_c\n",
      "ed_st_INSTRUCTION_EXPENDITURE_c\n",
      "ed_st_SUPPORT_SERVICES_EXPENDITURE_c\n",
      "ed_st_OTHER_EXPENDITURE_c\n",
      "ed_st_CAPITAL_OUTLAY_EXPENDITURE_c\n",
      "SectorCode\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df.columns)):\n",
    "    print(df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "col_start = df.columns.get_loc('income_n1_1')\n",
    "col_end = df.columns.get_loc('income_a19700_6')\n",
    "df_zip_columns = list(df.columns[col_start:col_end+1])\n",
    "for col in df_zip_columns:\n",
    "    df[col].fillna( df[col].mean(), inplace=True) \n",
    "col_start = df.columns.get_loc('ed_cty_ENROLL')\n",
    "col_end = df.columns.get_loc('ed_cty_TCAPOUT')\n",
    "df_ed_columns_1 = list(df.columns[col_start:col_end+1])\n",
    "for col in df_ed_columns_1:\n",
    "    df[col].fillna( df[col].mean(), inplace=True)\n",
    "col_start = df.columns.get_loc('ed_st_ENROLL')\n",
    "col_end = df.columns.get_loc('ed_st_CAPITAL_OUTLAY_EXPENDITURE')\n",
    "df_ed_columns_2 = list(df.columns[col_start:col_end+1])\n",
    "for col in df_ed_columns_2:\n",
    "    df[col].fillna( df[col].mean(), inplace=True)    \n",
    "    \n",
    "df['farm_Num_Farms_Supply'].fillna( 0, inplace=True)\n",
    "df['farm_NumShares'].fillna( 0, inplace=True)\n",
    "df['farm_CSA_organic'].fillna( 0, inplace=True)\n",
    "df['unemp_m_value'].fillna(df['unemp_m_value'].mean(), inplace=True)\n",
    "df['unemp_Rate'].fillna(df['unemp_Rate'].mean(), inplace=True)\n",
    "df['zillow_SizeRank'].fillna(df['zillow_SizeRank'].mean(), inplace=True)\n",
    "df['zillow_SizeRank.1'].fillna(df['zillow_SizeRank.1'].mean(), inplace=True)\n",
    "df['zillow_SizeRank.2'].fillna(df['zillow_SizeRank.2'].mean(), inplace=True)\n",
    "df['zillow_SizeRank.3'].fillna(df['zillow_SizeRank.3'].mean(), inplace=True)\n",
    "df['zillow_PctIncrease'].fillna(df['zillow_PctIncrease'].mean(), inplace=True)\n",
    "df['zillow_PctDecrease'].fillna(df['zillow_PctDecrease'].mean(), inplace=True)\n",
    "df['zillow_MedianValue'].fillna(df['zillow_MedianValue'].mean(), inplace=True)\n",
    "df['zillow_ZHVI'].fillna(df['zillow_ZHVI'].mean(), inplace=True)\n",
    "df['SP_Adj_Close'].interpolate(method='nearest', inplace=True)\n",
    "df['SP_Returns'].fillna(df['SP_Returns'].mean(), inplace=True)\n",
    "df['ag_Private_dollar'].fillna(df['ag_Private_dollar'].mean(), inplace=True)\n",
    "df['ag_Private_nom'].fillna(df['ag_Private_nom'].mean(), inplace=True)\n",
    "df['ag_Public_dollar'].fillna(df['ag_Public_dollar'].mean(), inplace=True)\n",
    "df['ag_Public_nom'].fillna(df['ag_Public_nom'].mean(), inplace=True)\n",
    "df['patent_Patent'].fillna(df['patent_Patent'].mean(), inplace=True)\n",
    "df['patent_Patent_frac'].fillna(df['patent_Patent_frac'].mean(), inplace=True)\n",
    "df['cci_CCI'].fillna(df['cci_CCI'].mean(), inplace=True)\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_borr = pd.get_dummies(df.ProjectState, prefix = 'Borr') \n",
    "df_lend = pd.get_dummies(df.ThirdPartyLender_State, prefix = 'Lend') \n",
    "df_cdc = pd.get_dummies(df.CDC_State, prefix = 'CDC') \n",
    "df_year = pd.get_dummies(df.ApprovalFiscalYear, prefix = 'appr') \n",
    "df_buis = pd.get_dummies(df.BusinessType, prefix = 'buis') \n",
    "df_sect = pd.get_dummies(df.SectorCode, prefix = 'sect') \n",
    "df_term = pd.get_dummies(df.TermInMonths, prefix = 'term') \n",
    "df_income = df[df_zip_columns] \n",
    "df_income = (df_income - df_income.min())/(df_income.max() - df_income.min()) \n",
    "df_ed_1 = df[df_ed_columns_1] \n",
    "df_ed_2 = df[df_ed_columns_2] \n",
    "data = df_sect \n",
    "data = pd.concat([data, df_year], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df_buis], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df.ThirdPartyDollars)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df.GrossApproval)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df_term], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df.SP_Adj_Close + 1)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df.bci_BCI)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df.cci_CCI)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df_lend], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df_borr], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df_cdc], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df.ag_Public_nom)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df.ag_Private_nom)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df.ag_Public_dollar)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df.ag_Private_dollar)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df.farm_Num_Farms_Supply], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df.farm_CSA_organic], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df.farm_NumShares], axis=1, join_axes=[data.index])\n",
    "\n",
    "\n",
    "data = pd.concat([data, df.unemp_m_value], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df.unemp_Rate], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df_income + 1)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df_ed_1 + 1)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df_ed_2 + 1)], axis=1, join_axes=[data.index])\n",
    "data = pd.concat([data, np.log(df['zillow_ZHVI'] + 1)], axis=1, join_axes=[data.index])\n",
    "data = pd.concat([data, np.log(df['zillow_SizeRank'] + 1)], axis=1, join_axes=[data.index])\n",
    "data = pd.concat([data, np.log(df['zillow_SizeRank.1'] + 1)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df['zillow_SizeRank.2'] + 1)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df['zillow_SizeRank.3'] + 1)], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, np.log(df.zillow_MedianValue + 1)], axis=1, join_axes=[data.index])\n",
    "\n",
    "data = (data-data.min())/(data.max()-data.min())\n",
    "\n",
    "#Do not normalize the data corresponding to potentially negative percentages \n",
    "data = pd.concat([data, df.zillow_PctDecrease], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df.zillow_PctIncrease], axis=1, join_axes=[data.index]) \n",
    "data = pd.concat([data, df.SP_Returns], axis=1, join_axes=[data.index])\n",
    "\n",
    "#Normalize data using max to min to bring values between 0 and 1. This will help learn faster for elu \n",
    "ordered_data = data \n",
    "data = data.as_matrix() \n",
    "labels = df['LoanStatus'].as_matrix() \n",
    "truth = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:101: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, input_dim=398, kernel_regularizer=<keras.reg..., kernel_initializer=\"normal\")`\n",
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:105: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, kernel_regularizer=<keras.reg..., kernel_initializer=\"normal\")`\n",
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, kernel_regularizer=<keras.reg..., kernel_initializer=\"normal\")`\n",
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:114: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, kernel_regularizer=<keras.reg..., kernel_initializer=\"normal\")`\n",
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:119: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, kernel_regularizer=<keras.reg..., kernel_initializer=\"normal\")`\n",
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:124: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, kernel_regularizer=<keras.reg..., kernel_initializer=\"normal\")`\n",
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:129: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, kernel_regularizer=<keras.reg..., kernel_initializer=\"normal\")`\n",
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, kernel_regularizer=<keras.reg..., kernel_initializer=\"normal\")`\n",
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:139: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, kernel_regularizer=<keras.reg..., kernel_initializer=\"normal\")`\n",
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:143: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_regularizer=<keras.reg..., units=1, kernel_initializer=\"normal\")`\n"
     ]
    }
   ],
   "source": [
    "data, labels = unison_shuffled_copies(data, labels)\n",
    "\n",
    "training_percentage = 0.92\n",
    "validation_percentage = 0.04\n",
    "cutoff = int(training_percentage*len(data))\n",
    "\n",
    "X_train = data[0:cutoff][:]\n",
    "Y_train = labels[0:cutoff]\n",
    "\n",
    "cutoff_2 = int((training_percentage+validation_percentage)*len(data))\n",
    "X_val = data[cutoff + 1:cutoff_2][:]\n",
    "Y_val = labels[cutoff + 1:cutoff_2]\n",
    "X_test = data[cutoff_2 + 1:][:]\n",
    "Y_test = labels[cutoff_2 + 1:]\n",
    "X_train = X_train.astype('float32') \n",
    "X_val = X_val.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#Switch between NN and basic Sigmoid function by setting this flag. \n",
    "#Note: Update Hyperparameters accordingly for better performance\n",
    "\n",
    "implementNN = True\n",
    "\n",
    "#Note: mode 1 is a deep model whereas mode 2 is less deep and even more shallow for mode 3. This can be adjusted as you like.\n",
    "#elu are ideal for the normalized data\n",
    "mode = 2\n",
    "\n",
    "model = Sequential() \n",
    "num_features = data.shape[1]\n",
    "if implementNN  and mode == 1:\n",
    "    \n",
    "    model.add(Dense(32, input_dim=num_features, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(64, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    " \n",
    "    model.add(Dense(128, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(256, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(512, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1024, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(2048, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1024, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(128, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(64, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(32, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    model.add(Dense(1, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "elif implementNN and mode == 2 :\n",
    "    \n",
    "    model.add(Dense(32, input_dim=num_features, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    model.add(Dense(64, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    " \n",
    "    model.add(Dense(128, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(512, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.3))    \n",
    "    \n",
    "    model.add(Dense(256, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(128, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(64, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(32, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    model.add(Dense(output_dim = 1, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "elif implementNN and mode == 3 :\n",
    "    \n",
    "    model.add(Dense(32, input_dim=num_features, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    model.add(Dense(64, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    " \n",
    "    model.add(Dense(128, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    model.add(Dense(256, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(128, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0.0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    model.add(Dense(64, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    model.add(Dense(32, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    \n",
    "    model.add(Dense(output_dim = 1, init='normal', kernel_regularizer=L1L2(l1=0.0, l2=0)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "else :\n",
    "    #Note : One layer Neural Network is the same as a logit model if sigmoid is activation\n",
    "    model.add(Dense(output_dim = 1, kernel_regularizer=L1L2(l1=0.0, l2=0.0),input_dim=num_features, activation='sigmoid',  init='normal'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 368,293\n",
      "Trainable params: 365,347\n",
      "Non-trainable params: 2,946\n",
      "_________________________________________________________________\n",
      "Train on 50421 samples, validate on 2191 samples\n",
      "Epoch 1/200\n",
      "50421/50421 [==============================] - 40s 801us/step - loss: 0.1664 - acc: 0.9378 - auc_roc: 0.8379 - val_loss: 0.1781 - val_acc: 0.9343 - val_auc_roc: 0.8733\n",
      "Epoch 2/200\n",
      "50421/50421 [==============================] - 29s 583us/step - loss: 0.1581 - acc: 0.9394 - auc_roc: 0.8798 - val_loss: 0.1754 - val_acc: 0.9352 - val_auc_roc: 0.8838\n",
      "Epoch 3/200\n",
      "50421/50421 [==============================] - 31s 606us/step - loss: 0.1556 - acc: 0.9401 - auc_roc: 0.8862 - val_loss: 0.1750 - val_acc: 0.9347 - val_auc_roc: 0.8886\n",
      "Epoch 4/200\n",
      "50421/50421 [==============================] - 27s 534us/step - loss: 0.1534 - acc: 0.9415 - auc_roc: 0.8903 - val_loss: 0.1853 - val_acc: 0.9375 - val_auc_roc: 0.8915\n",
      "Epoch 5/200\n",
      "50421/50421 [==============================] - 27s 536us/step - loss: 0.1531 - acc: 0.9415 - auc_roc: 0.8925 - val_loss: 0.1768 - val_acc: 0.9375 - val_auc_roc: 0.8933\n",
      "Epoch 6/200\n",
      "50421/50421 [==============================] - 23s 461us/step - loss: 0.1523 - acc: 0.9424 - auc_roc: 0.8940 - val_loss: 0.1755 - val_acc: 0.9352 - val_auc_roc: 0.8947\n",
      "Epoch 7/200\n",
      "50421/50421 [==============================] - 23s 455us/step - loss: 0.1506 - acc: 0.9431 - auc_roc: 0.8955 - val_loss: 0.1847 - val_acc: 0.9347 - val_auc_roc: 0.8961\n",
      "Epoch 8/200\n",
      "50421/50421 [==============================] - 24s 468us/step - loss: 0.1497 - acc: 0.9419 - auc_roc: 0.8968 - val_loss: 0.1815 - val_acc: 0.9352 - val_auc_roc: 0.8974\n",
      "Epoch 9/200\n",
      "50421/50421 [==============================] - 25s 490us/step - loss: 0.1495 - acc: 0.9427 - auc_roc: 0.8979 - val_loss: 0.1769 - val_acc: 0.9347 - val_auc_roc: 0.8984\n",
      "Epoch 10/200\n",
      "50421/50421 [==============================] - 25s 500us/step - loss: 0.1484 - acc: 0.9431 - auc_roc: 0.8988 - val_loss: 0.1797 - val_acc: 0.9352 - val_auc_roc: 0.8994\n",
      "Epoch 11/200\n",
      "50421/50421 [==============================] - 25s 494us/step - loss: 0.1478 - acc: 0.9430 - auc_roc: 0.8999 - val_loss: 0.1807 - val_acc: 0.9347 - val_auc_roc: 0.9004\n",
      "Epoch 12/200\n",
      "50421/50421 [==============================] - 24s 475us/step - loss: 0.1474 - acc: 0.9431 - auc_roc: 0.9006 - val_loss: 0.1856 - val_acc: 0.9375 - val_auc_roc: 0.9011\n",
      "Epoch 13/200\n",
      "50421/50421 [==============================] - 24s 478us/step - loss: 0.1465 - acc: 0.9433 - auc_roc: 0.9015 - val_loss: 0.1799 - val_acc: 0.9338 - val_auc_roc: 0.9019\n",
      "Epoch 14/200\n",
      "50421/50421 [==============================] - 25s 492us/step - loss: 0.1455 - acc: 0.9443 - auc_roc: 0.9021 - val_loss: 0.1841 - val_acc: 0.9370 - val_auc_roc: 0.9026\n",
      "Epoch 15/200\n",
      "50421/50421 [==============================] - 24s 475us/step - loss: 0.1456 - acc: 0.9438 - auc_roc: 0.9028 - val_loss: 0.1908 - val_acc: 0.9352 - val_auc_roc: 0.9033\n",
      "Epoch 16/200\n",
      "50421/50421 [==============================] - 27s 533us/step - loss: 0.1450 - acc: 0.9445 - auc_roc: 0.9035 - val_loss: 0.1813 - val_acc: 0.9334 - val_auc_roc: 0.9038\n",
      "Epoch 17/200\n",
      "50421/50421 [==============================] - 29s 567us/step - loss: 0.1441 - acc: 0.9446 - auc_roc: 0.9041 - val_loss: 0.1800 - val_acc: 0.9375 - val_auc_roc: 0.9044\n",
      "Epoch 18/200\n",
      "50421/50421 [==============================] - 31s 622us/step - loss: 0.1438 - acc: 0.9445 - auc_roc: 0.9047 - val_loss: 0.1827 - val_acc: 0.9329 - val_auc_roc: 0.9050\n",
      "Epoch 19/200\n",
      "50421/50421 [==============================] - 32s 633us/step - loss: 0.1431 - acc: 0.9436 - auc_roc: 0.9054 - val_loss: 0.1816 - val_acc: 0.9352 - val_auc_roc: 0.9056\n",
      "Epoch 20/200\n",
      "50421/50421 [==============================] - 28s 546us/step - loss: 0.1432 - acc: 0.9443 - auc_roc: 0.9058 - val_loss: 0.1842 - val_acc: 0.9334 - val_auc_roc: 0.9062\n",
      "Epoch 21/200\n",
      "50421/50421 [==============================] - 31s 621us/step - loss: 0.1419 - acc: 0.9450 - auc_roc: 0.9064 - val_loss: 0.1839 - val_acc: 0.9347 - val_auc_roc: 0.9067\n",
      "Epoch 22/200\n",
      "50421/50421 [==============================] - 31s 612us/step - loss: 0.1413 - acc: 0.9445 - auc_roc: 0.9070 - val_loss: 0.1814 - val_acc: 0.9325 - val_auc_roc: 0.9073\n",
      "Epoch 23/200\n",
      "50421/50421 [==============================] - 37s 738us/step - loss: 0.1416 - acc: 0.9443 - auc_roc: 0.9076 - val_loss: 0.1870 - val_acc: 0.9375 - val_auc_roc: 0.9078\n",
      "Epoch 24/200\n",
      "50421/50421 [==============================] - 35s 690us/step - loss: 0.1404 - acc: 0.9452 - auc_roc: 0.9080 - val_loss: 0.1897 - val_acc: 0.9352 - val_auc_roc: 0.9083\n",
      "Epoch 25/200\n",
      "50421/50421 [==============================] - 31s 615us/step - loss: 0.1402 - acc: 0.9456 - auc_roc: 0.9085 - val_loss: 0.1895 - val_acc: 0.9297 - val_auc_roc: 0.9087\n",
      "Epoch 26/200\n",
      "50421/50421 [==============================] - 30s 598us/step - loss: 0.1390 - acc: 0.9460 - auc_roc: 0.9090 - val_loss: 0.1864 - val_acc: 0.9375 - val_auc_roc: 0.9092\n",
      "Epoch 27/200\n",
      "50421/50421 [==============================] - 38s 758us/step - loss: 0.1392 - acc: 0.9460 - auc_roc: 0.9095 - val_loss: 0.1873 - val_acc: 0.9347 - val_auc_roc: 0.909794\n",
      "Epoch 28/200\n",
      "50421/50421 [==============================] - 40s 790us/step - loss: 0.1382 - acc: 0.9455 - auc_roc: 0.9099 - val_loss: 0.1921 - val_acc: 0.9270 - val_auc_roc: 0.9102\n",
      "Epoch 29/200\n",
      "50421/50421 [==============================] - 38s 745us/step - loss: 0.1383 - acc: 0.9464 - auc_roc: 0.9104 - val_loss: 0.1889 - val_acc: 0.9343 - val_auc_roc: 0.9106\n",
      "Epoch 30/200\n",
      "50421/50421 [==============================] - 40s 784us/step - loss: 0.1373 - acc: 0.9460 - auc_roc: 0.9108 - val_loss: 0.1864 - val_acc: 0.9320 - val_auc_roc: 0.9110\n",
      "Epoch 31/200\n",
      "50421/50421 [==============================] - 37s 727us/step - loss: 0.1368 - acc: 0.9469 - auc_roc: 0.9113 - val_loss: 0.1841 - val_acc: 0.9361 - val_auc_roc: 0.9115\n",
      "Epoch 32/200\n",
      "50421/50421 [==============================] - 35s 703us/step - loss: 0.1370 - acc: 0.9469 - auc_roc: 0.9117 - val_loss: 0.1897 - val_acc: 0.9343 - val_auc_roc: 0.9119\n",
      "Epoch 33/200\n",
      "50421/50421 [==============================] - 37s 738us/step - loss: 0.1359 - acc: 0.9466 - auc_roc: 0.9121 - val_loss: 0.1879 - val_acc: 0.9325 - val_auc_roc: 0.9123\n",
      "Epoch 34/200\n",
      "50421/50421 [==============================] - 35s 692us/step - loss: 0.1350 - acc: 0.9469 - auc_roc: 0.9125 - val_loss: 0.1951 - val_acc: 0.9325 - val_auc_roc: 0.9127\n",
      "Epoch 35/200\n",
      "50421/50421 [==============================] - 40s 802us/step - loss: 0.1355 - acc: 0.9473 - auc_roc: 0.9128 - val_loss: 0.1930 - val_acc: 0.9302 - val_auc_roc: 0.9131\n",
      "Epoch 36/200\n",
      "17664/50421 [=========>....................] - ETA: 23s - loss: 0.1348 - acc: 0.9459 - auc_roc: 0.9132"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 200\n",
    "opt = optimizers.Adagrad(lr=0.08)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics = ['accuracy', auc_roc]) \n",
    "# \n",
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), verbose = 1,epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    weights = (layer.get_weights()) # list of numpy arrays\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "print('Test ROC', score[2])\n",
    "#weights = weights[0]\n",
    "\n",
    "Y_pred = model.predict_proba(X_train)\n",
    "print(roc_auc_score(Y_train, Y_pred))\n",
    "\n",
    "Y_pred = model.predict_proba(X_test)\n",
    "print(roc_auc_score(Y_test, Y_pred))\n",
    "\n",
    "full_data = ordered_data.as_matrix()\n",
    "ordered_probabilities = model.predict_proba(full_data)\n",
    "print(roc_auc_score(truth, ordered_probabilities))\n",
    "df['default_probabilities'] = ordered_probabilities\n",
    "df['LoanStatus'].replace(1, 'CHGOFF', inplace=True)\n",
    "df['LoanStatus'].replace(0, 'PIF', inplace=True)\n",
    "for i in range(len(ordered_probabilities)):\n",
    "    print(ordered_probabilities[i], \" \", df.LoanStatus[i])\n",
    "df.to_csv(\"SBA_Data_with_Default_Probabilities_\" + str(year_thresh), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(df['LoanStatus'], df['default_probabilities'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, 'g', label = ' 8 Layer Network: AUC = %0.4f' % roc_auc)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic for General Probability of Default')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
